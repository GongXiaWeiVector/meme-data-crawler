use crate::types::{ImageMetadata, DuplicateRecord};
use crate::file_manager::FileManager;
use anyhow::Result;
use std::collections::HashMap;
use std::fs;

/// å»é‡åˆ†æå™¨
pub struct DedupAnalyzer {
    file_manager: FileManager,
}

impl DedupAnalyzer {
    pub fn new(data_dir: &str) -> Result<Self> {
        Ok(Self {
            file_manager: FileManager::new(data_dir)?,
        })
    }
    
    /// åˆ†æé‡è¤‡åœ–ç‰‡
    pub fn analyze(&self) -> Result<DedupResult> {
        println!("ğŸ“– è®€å–æ‰€æœ‰ metadata...");
        let all_metadata = self.file_manager.load_all_metadata()?;
        
        println!("ğŸ” åˆ†æä¸­... (å…± {} å¼µåœ–ç‰‡)", all_metadata.len());
        
        // hash -> Vec<ImageMetadata>
        let mut hash_map: HashMap<String, Vec<ImageMetadata>> = HashMap::new();
        
        for metadata in all_metadata {
            hash_map
                .entry(metadata.content_hash.clone())
                .or_insert_with(Vec::new)
                .push(metadata);
        }
        
        // æ‰¾å‡ºé‡è¤‡çš„
        let mut duplicates = Vec::new();
        let mut unique_count = 0;
        let mut duplicate_count = 0;
        
        for (hash, items) in hash_map.iter() {
            if items.len() > 1 {
                // æœ‰é‡è¤‡
                duplicate_count += items.len() - 1; // ä¿ç•™ä¸€å€‹ï¼Œå…¶é¤˜ç®—é‡è¤‡
                
                let record = DuplicateRecord {
                    content_hash: hash.clone(),
                    files: items.iter().map(|m| m.filename.clone()).collect(),
                };
                duplicates.push(record);
            } else {
                unique_count += 1;
            }
        }
        
        Ok(DedupResult {
            total_images: hash_map.values().map(|v| v.len()).sum(),
            unique_images: hash_map.len(),
            duplicate_groups: duplicates.len(),
            duplicate_images: duplicate_count,
            duplicates,
        })
    }
    
    /// æ¨™è¨˜é‡è¤‡åœ–ç‰‡ï¼ˆå¯«å…¥æª”æ¡ˆï¼‰
    pub fn mark_duplicates(&self, result: &DedupResult) -> Result<()> {
        println!("ğŸ’¾ å„²å­˜é‡è¤‡åœ–ç‰‡å ±å‘Š...");
        
        // å„²å­˜åˆ° duplicates.json
        let json = serde_json::to_string_pretty(&result.duplicates)?;
        fs::write("./data/duplicates.json", json)?;
        
        println!("âœ… å ±å‘Šå·²å„²å­˜åˆ° ./data/duplicates.json");
        
        Ok(())
    }
    
    /// è‡ªå‹•åˆªé™¤é‡è¤‡åœ–ç‰‡ï¼ˆä¿ç•™ç¬¬ä¸€å€‹ï¼‰
    pub fn remove_duplicates(&self, result: &DedupResult, dry_run: bool) -> Result<()> {
        if dry_run {
            println!("ğŸ” é è¦½æ¨¡å¼ï¼šä¸æœƒå¯¦éš›åˆªé™¤æª”æ¡ˆ");
        } else {
            println!("âš ï¸  è­¦å‘Šï¼šå³å°‡åˆªé™¤é‡è¤‡åœ–ç‰‡ï¼");
        }
        
        let mut removed_count = 0;
        
        for dup_group in &result.duplicates {
            // ä¿ç•™ç¬¬ä¸€å€‹ï¼Œåˆªé™¤å…¶é¤˜
            for (i, filename) in dup_group.files.iter().enumerate() {
                if i == 0 {
                    println!("  âœ… ä¿ç•™: {}", filename);
                    continue;
                }
                
                let path = self.file_manager.get_image_path(filename);
                
                if dry_run {
                    println!("  ğŸ—‘ï¸  [é è¦½] å°‡åˆªé™¤: {}", filename);
                } else {
                    match fs::remove_file(&path) {
                        Ok(_) => {
                            println!("  âŒ å·²åˆªé™¤: {}", filename);
                            removed_count += 1;
                        }
                        Err(e) => {
                            eprintln!("  âš ï¸  åˆªé™¤å¤±æ•— ({}): {}", filename, e);
                        }
                    }
                }
            }
            println!();
        }
        
        if !dry_run {
            println!("âœ… å·²åˆªé™¤ {} å€‹é‡è¤‡æª”æ¡ˆ", removed_count);
        }
        
        Ok(())
    }
}

/// å»é‡çµæœ
#[derive(Debug)]
pub struct DedupResult {
    /// ç¸½åœ–ç‰‡æ•¸
    pub total_images: usize,
    /// å”¯ä¸€åœ–ç‰‡æ•¸
    pub unique_images: usize,
    /// é‡è¤‡çµ„æ•¸
    pub duplicate_groups: usize,
    /// é‡è¤‡åœ–ç‰‡æ•¸
    pub duplicate_images: usize,
    /// é‡è¤‡è¨˜éŒ„
    pub duplicates: Vec<DuplicateRecord>,
}

impl DedupResult {
    /// é¡¯ç¤ºå ±å‘Š
    pub fn print_report(&self) {
        println!("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
        println!("â•‘     ğŸ” é‡è¤‡åœ–ç‰‡åˆ†æå ±å‘Š         â•‘");
        println!("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£");
        println!("â•‘ ç¸½åœ–ç‰‡æ•¸:   {:>18} â•‘", self.total_images);
        println!("â•‘ å”¯ä¸€åœ–ç‰‡:   {:>18} â•‘", self.unique_images);
        println!("â•‘ é‡è¤‡çµ„æ•¸:   {:>18} â•‘", self.duplicate_groups);
        println!("â•‘ é‡è¤‡åœ–ç‰‡:   {:>18} â•‘", self.duplicate_images);
        println!("â•‘ é‡è¤‡ç‡:     {:>17.1}% â•‘", 
            (self.duplicate_images as f64 / self.total_images as f64) * 100.0);
        println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
        
        if self.duplicate_groups > 0 {
            println!("ğŸ“‹ é‡è¤‡çµ„è©³æƒ… (å‰ 10 çµ„):\n");
            
            for (i, dup) in self.duplicates.iter().take(10).enumerate() {
                println!("  çµ„ {}: {} å¼µé‡è¤‡", i + 1, dup.files.len());
                println!("  Hash: {}", &dup.content_hash[..16]);
                for (j, file) in dup.files.iter().enumerate() {
                    let marker = if j == 0 { "âœ… ä¿ç•™" } else { "âŒ é‡è¤‡" };
                    println!("    {} {}", marker, file);
                }
                println!();
            }
            
            if self.duplicates.len() > 10 {
                println!("  ... é‚„æœ‰ {} çµ„é‡è¤‡", self.duplicates.len() - 10);
            }
        }
    }
}